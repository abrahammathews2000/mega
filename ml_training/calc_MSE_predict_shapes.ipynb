{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code is used to compute the MSE\n",
    "# between predicted shape and actual shape\n",
    "# Steps involves:\n",
    "# 1. Fold the original image horizontally at the center\n",
    "# (Mirror the top part on to the bottom and add,\n",
    "# then give pixel value 1 to all values other than 0)\n",
    "# 2. Fold the predicted image similarly \n",
    "# (Mirror the top part on to the bottom and add,\n",
    "# then normalize the image)\n",
    "\n",
    "# Last section contains the all the functions to fold and calc MSE\n",
    "# Other sections are used to experiment with the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "\n",
    "# Import TF and check for GPU\n",
    "\n",
    "import tensorflow as tf\n",
    "print(tf.config.list_physical_devices('GPU'))\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from tensorflow.keras.models import save_model, load_model\n",
    "import sys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_shape_dir  = '../data/data_npy/shape_npy/shape_filled8.npy'\n",
    "# test_shape = np.load(test_shape_dir)\n",
    "# # Normalize the image, convert to opacity map\n",
    "# ## Test Set\n",
    "# test_shape = test_shape/np.amax(test_shape)\n",
    "# test_shape_where_0 = np.where(test_shape == 0)\n",
    "# test_shape_where_1 = np.where(test_shape == 1)\n",
    "# test_shape[test_shape_where_0] = 1  # 1 represent the shape (1 opacity)\n",
    "# test_shape[test_shape_where_1] = 0  # 0 represent background (0 opacity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Test Dataset\n",
    "# test_shape_dir = '/home/abraham/Documents/ms_proj_shape_lc_gen/data_npy/shape_npy/shape_filled8.npy'\n",
    "# test_lc_dir = '/home/abraham/Documents/ms_proj_shape_lc_gen/data_npy/lc_npy/lc_dict_8.npy'\n",
    "test_lc_dir = '../data/data_npy/lc_npy/lc_dict_8.npy'\n",
    "test_shape_dir  = '../data/data_npy/shape_npy/shape_filled8.npy'\n",
    "\n",
    "\n",
    "test_lc = np.load(test_lc_dir)\n",
    "test_shape = np.load(test_shape_dir)\n",
    "# Check equality of number of dataset\n",
    "if len(test_lc)==len(test_shape):\n",
    "    print(\"test Set: No. of LC = No. of shapes\")\n",
    "else:\n",
    "    sys.exit(\"EXIT: testn Set: No. of LC != No. of shapes\")\n",
    "\n",
    "# Normalize the image, convert to opacity map\n",
    "## Test Set\n",
    "test_shape = test_shape/np.amax(test_shape)\n",
    "test_shape_where_0 = np.where(test_shape == 0)\n",
    "test_shape_where_1 = np.where(test_shape == 1)\n",
    "test_shape[test_shape_where_0] = 1  # 1 represent the shape (1 opacity)\n",
    "test_shape[test_shape_where_1] = 0  # 0 represent background (0 opacity)\n",
    "\n",
    "\n",
    "# Normalize the lightcurves\n",
    "## - Test Set\n",
    "test_lc_scaled = np.zeros(test_lc.shape)\n",
    "for i in np.arange(len(test_lc_scaled)):\n",
    "    test_lc_scaled[i] = (test_lc[i] - np.amin(test_lc[i]))/(np.amax(test_lc[i]) - np.amin(test_lc[i]))\n",
    "\n",
    "# Append with ones\n",
    "## - Test Set\n",
    "test_lc_scaled_append = np.ones((test_lc.shape[0],120))\n",
    "for i in np.arange(len(test_lc_scaled)):\n",
    "    test_lc_scaled_append[i,10:110] = test_lc_scaled[i]\n",
    "print(\"Extended the light curves\")\n",
    "\n",
    "# Function to Add noise to Test light curve\n",
    "def add_noise(test_lc_scaled_append,SNR):\n",
    "    std_dev = 1/SNR\n",
    "    test_lc_scaled_append_noise = np.ones(test_lc_scaled_append.shape)\n",
    "    rng = np.random.default_rng()\n",
    "\n",
    "    for i in np.arange(len(test_lc_scaled_append)):\n",
    "        noise_temp = np.random.normal(loc=0.0, scale=std_dev, size=len(test_lc_scaled_append[i]))\n",
    "        rng.shuffle(noise_temp)\n",
    "        test_lc_scaled_append_noise[i] = test_lc_scaled_append[i] + noise_temp\n",
    "    return test_lc_scaled_append_noise\n",
    "\n",
    "# Add noise to the light curve\n",
    "test_lc_SNR500 =add_noise(test_lc_scaled_append,SNR=500)\n",
    "test_lc_SNR200 =add_noise(test_lc_scaled_append,SNR=200)\n",
    "test_lc_SNR150 =add_noise(test_lc_scaled_append,SNR=150)\n",
    "test_lc_SNR100 =add_noise(test_lc_scaled_append,SNR=100)\n",
    "test_lc_SNR75 =add_noise(test_lc_scaled_append,SNR=75)\n",
    "test_lc_SNR50 =add_noise(test_lc_scaled_append,SNR=50)\n",
    "test_lc_SNR35 =add_noise(test_lc_scaled_append,SNR=35)\n",
    "test_lc_SNR20 =add_noise(test_lc_scaled_append,SNR=20)\n",
    "\n",
    "# Experiment 2\n",
    "# Switch on one MODEL and test on LC with different SNR\n",
    "# Function to normalize predicted shape\n",
    "def normalize_shape(test_predict_shape):\n",
    "    test_predict_shape_normalized = np.zeros(test_predict_shape.shape)\n",
    "    for i in np.arange(len(test_predict_shape)):\n",
    "        test_predict_shape_normalized[i] = (test_predict_shape[i] - np.amin(test_predict_shape[i]))/(np.amax(test_predict_shape[i]) - np.amin(test_predict_shape[i]))\n",
    "    print(\"Normalized the predicted shape\")\n",
    "    return test_predict_shape_normalized\n",
    "\n",
    "#Load ML model\n",
    "tf.keras.backend.clear_session()\n",
    "model_SNR = load_model(\"../ml_model/sep22_singleModel_uniform_SNR/model_sep22_unf_50_500_v1.h5\")\n",
    "\n",
    "results = model_SNR.evaluate(test_lc_SNR500, test_shape, batch_size=128,verbose=0)\n",
    "print(\"SNR = 500. Loss ->\",results)\n",
    "test_predict_shape_SNR500 = model_SNR.predict(test_lc_SNR500)\n",
    "# test_predict_shape_SNR500 = normalize_shape(test_predict_shape_SNR500)\n",
    "\n",
    "results = model_SNR.evaluate(test_lc_SNR200, test_shape, batch_size=128,verbose=0)\n",
    "print(\"SNR = 200. Loss ->\",results)\n",
    "test_predict_shape_SNR200 = model_SNR.predict(test_lc_SNR200)\n",
    "# test_predict_shape_SNR200 = normalize_shape(test_predict_shape_SNR200)\n",
    "\n",
    "results = model_SNR.evaluate(test_lc_SNR150, test_shape, batch_size=128,verbose=0)\n",
    "print(\"SNR = 150. Loss ->\",results)\n",
    "test_predict_shape_SNR150 = model_SNR.predict(test_lc_SNR150)\n",
    "# test_predict_shape_SNR150 = normalize_shape(test_predict_shape_SNR150)\n",
    "\n",
    "results = model_SNR.evaluate(test_lc_SNR100, test_shape, batch_size=128,verbose=0)\n",
    "print(\"SNR = 100. Loss ->\",results)\n",
    "test_predict_shape_SNR100 = model_SNR.predict(test_lc_SNR100)\n",
    "# test_predict_shape_SNR100 = normalize_shape(test_predict_shape_SNR100)\n",
    "\n",
    "results = model_SNR.evaluate(test_lc_SNR75, test_shape, batch_size=128,verbose=0)\n",
    "print(\"SNR = 75. Loss ->\",results)\n",
    "test_predict_shape_SNR75 = model_SNR.predict(test_lc_SNR75)\n",
    "# test_predict_shape_SNR75 = normalize_shape(test_predict_shape_SNR75)\n",
    "\n",
    "results = model_SNR.evaluate(test_lc_SNR50, test_shape, batch_size=128,verbose=0)\n",
    "print(\"SNR = 50. Loss ->\",results)\n",
    "test_predict_shape_SNR50 = model_SNR.predict(test_lc_SNR50)\n",
    "# test_predict_shape_SNR50 = normalize_shape(test_predict_shape_SNR50)\n",
    "\n",
    "# Plot predicted shapes\n",
    "num = 5\n",
    "fig,ax=plt.subplots(num,7, figsize=(13,5), gridspec_kw={ 'width_ratios': [1,1,1,1,1,1,1],\n",
    "        'wspace': 0.1,'hspace': 0.4})\n",
    "plt.rcParams['figure.dpi'] = 1000\n",
    "plt.rcParams.update({'font.size': 8})\n",
    "\n",
    "ax[0][0].set_title('Original',size=8)\n",
    "ax[0][1].set_title('SNR = 500',size=8)\n",
    "ax[0][2].set_title('SNR = 200',size=8)\n",
    "ax[0][3].set_title('SNR = 150',size=8)\n",
    "ax[0][4].set_title('SNR = 100',size=8)\n",
    "ax[0][5].set_title('SNR = 75',size=8)\n",
    "ax[0][6].set_title('SNR = 50',size=8)\n",
    "\n",
    "\n",
    "\n",
    "temp = np.linspace(0, len(test_lc_scaled_append)-1,len(test_lc_scaled_append))\n",
    "index_test_array = np.random.choice(temp, size=(num,), replace=False)\n",
    "\n",
    "for i in range(num):\n",
    "    k =  i # int(index_test_array[i]) # random.randint(0, len(test_lc_scaled_append)-1) # i\n",
    "    print(\"k = \",k)\n",
    "    ax[i][0].tick_params(left = False, right = False , labelleft = False ,labelbottom = False, bottom = False)\n",
    "    ax[i][1].tick_params(left = False, right = False , labelleft = False ,labelbottom = False, bottom = False)\n",
    "    ax[i][2].tick_params(left = False, right = False , labelleft = False ,labelbottom = False, bottom = False)\n",
    "    ax[i][3].tick_params(left = False, right = False , labelleft = False ,labelbottom = False, bottom = False)\n",
    "    ax[i][4].tick_params(left = False, right = False , labelleft = False ,labelbottom = False, bottom = False)\n",
    "    ax[i][5].tick_params(left = False, right = False , labelleft = False ,labelbottom = False, bottom = False)\n",
    "    ax[i][6].tick_params(left = False, right = False , labelleft = False ,labelbottom = False, bottom = False)\n",
    "\n",
    "    img = ax[i][0].imshow(test_shape[k],cmap='inferno')\n",
    "    plt.colorbar(img)  \n",
    "\n",
    "    img = ax[i][1].imshow(test_predict_shape_SNR500[k],cmap='inferno')\n",
    "    plt.colorbar(img)   \n",
    "\n",
    "    img = ax[i][2].imshow(test_predict_shape_SNR200[k],cmap='inferno')\n",
    "    plt.colorbar(img)   \n",
    "\n",
    "    img = ax[i][3].imshow(test_predict_shape_SNR150[k],cmap='inferno')\n",
    "    plt.colorbar(img)     \n",
    "\n",
    "    img = ax[i][4].imshow(test_predict_shape_SNR100[k],cmap='inferno')\n",
    "    plt.colorbar(img)  \n",
    "\n",
    "    img = ax[i][5].imshow(test_predict_shape_SNR75[k],cmap='inferno')\n",
    "    plt.colorbar(img)     \n",
    "\n",
    "    img = ax[i][6].imshow(test_predict_shape_SNR50[k],cmap='inferno')\n",
    "    plt.colorbar(img)\n",
    "\n",
    "plt.suptitle('Test Dataset Prediction for same shape but with light curve with different SNR')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verification\n",
    "num = 3\n",
    "fig,ax=plt.subplots(num,3, figsize=(4,3), gridspec_kw={ 'width_ratios': [1,1,1],\n",
    "        'wspace': 0.2,'hspace': 0.4})\n",
    "plt.rcParams['figure.dpi'] = 400\n",
    "\n",
    "ax[0][1].set_title('Shape',size=10)\n",
    "\n",
    "# advance = 60\n",
    "\n",
    "i = 0\n",
    "for i in np.arange(0,num):\n",
    "    k = np.random.randint(0, len(test_shape)-1)\n",
    "    ax[i][0].tick_params(left = False, right = False , labelleft = False ,labelbottom = False, bottom = False)\n",
    "    img = ax[i][0].imshow(test_shape[k],cmap='inferno')\n",
    "    plt.colorbar(img)\n",
    "    \n",
    "    k = np.random.randint(0, len(test_shape)-1)\n",
    "    ax[i][1].tick_params(left = False, right = False , labelleft = False ,labelbottom = False, bottom = False)\n",
    "    img = ax[i][1].imshow(test_shape[k],cmap='inferno')\n",
    "    plt.colorbar(img)\n",
    "    \n",
    "    k = np.random.randint(0, len(test_shape)-1)\n",
    "    ax[i][2].tick_params(left = False, right = False , labelleft = False ,labelbottom = False, bottom = False)\n",
    "    img = ax[i][2].imshow(test_shape[k],cmap='inferno')\n",
    "    plt.colorbar(img)\n",
    "\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def fold_original_image(org_image):\n",
    "#     # Fold a single dataset shape\n",
    "#     # image = np.zeros((int(org_image.shape[0]/2),int(org_image.shape[1])))\n",
    "#     image_top = org_image[0:int(org_image.shape[0]/2),:]\n",
    "#     image_bottom = org_image[int(org_image.shape[0]/2):,:]\n",
    "#     image_bottom_flip = np.flipud(image_bottom)\n",
    "#     folded_image = image_bottom_flip+image_top\n",
    "#     # folded_image_normalized = (folded_image - np.amin(folded_image))/(np.amax(folded_image) - np.amin(folded_image))\n",
    "#     folded_image[folded_image>0] = 1\n",
    "#     return(folded_image)\n",
    "\n",
    "\n",
    "# # Code to test the above function\n",
    "# index_compare = 19\n",
    "# original_test = test_shape[int(index_compare)]\n",
    "# fold_test_shape = fold_original_image(original_test)\n",
    "\n",
    "# print(\"fold_test_shape.shape = \",fold_test_shape.shape)\n",
    "\n",
    "# fig, ax = plt.subplots(1, 2, figsize=(12, 4))\n",
    "# original = test_shape[0]\n",
    "# im = ax[0].imshow(original_test, cmap='inferno')\n",
    "# ax[0].set_title('Original image')\n",
    "# plt.colorbar(im)\n",
    "\n",
    "# im = ax[1].imshow(fold_test_shape, cmap='inferno')\n",
    "# ax[1].set_title('Normalized output')\n",
    "# plt.colorbar(im)\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def fold_predicted_image(predicted_image):\n",
    "#     # Fold a single predicted image\n",
    "#     image_top = predicted_image[0:int(predicted_image.shape[0]/2),:]\n",
    "#     image_bottom = predicted_image[int(predicted_image.shape[0]/2):,:]\n",
    "#     image_bottom_flip = np.flipud(image_bottom)\n",
    "#     folded_predicted_image = image_bottom_flip+image_top\n",
    "#     folded_image_normalized = (folded_predicted_image - np.amin(folded_predicted_image))/(np.amax(folded_predicted_image) - np.amin(folded_predicted_image))\n",
    "#     # folded_image[folded_image>0] = 1\n",
    "#     return(folded_image_normalized)\n",
    "\n",
    "\n",
    "# # Code to test the above function\n",
    "# original_predict = test_predict_shape_SNR500[int(index_compare)]\n",
    "# folded_predicted_image = fold_predicted_image(original_predict)\n",
    "# print(\"folded_predicted_image.shape = \",folded_predicted_image.shape)\n",
    "\n",
    "# fig, ax = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# im = ax[0].imshow(original_predict, cmap='inferno')\n",
    "# ax[0].set_title('Original image')\n",
    "# plt.colorbar(im)\n",
    "\n",
    "# im = ax[1].imshow(folded_predicted_image, cmap='inferno')\n",
    "# ax[1].set_title('Normalized output')\n",
    "# plt.colorbar(im)\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MSE = np.mean((fold_test_shape-folded_predicted_image)**2)\n",
    "# print(MSE)\n",
    "\n",
    "# MSE = np.mean((original_test-original_predict)**2)\n",
    "# print(MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fold_original_image_array(org_image_array):\n",
    "    # Return an array containing folding each 2d shape\n",
    "    # print('org_image_array = ',org_image_array.shape)\n",
    "    folded_org_image_array = np.zeros((int(org_image_array.shape[0]),int(org_image_array.shape[1]/2),int(org_image_array.shape[2]) ))\n",
    "    # print('folded_org_image_array = ',folded_org_image_array.shape)\n",
    "    for i in np.arange(len(org_image_array)):\n",
    "        image_top = org_image_array[i,0:int(org_image_array.shape[1]/2),:]\n",
    "        # print('image_top.shape = ',image_top.shape)\n",
    "        image_bottom = org_image_array[i,int(org_image_array.shape[1]/2):,:]\n",
    "        # print(\"image_bottom.shape = \",image_bottom.shape)\n",
    "        image_bottom_flip = np.flipud(image_bottom)\n",
    "        # print('folded_org_image_array[i].shape = ',folded_org_image_array[i].shape)\n",
    "        folded_org_image_array[i] = image_bottom_flip+image_top\n",
    "    # folded_image_normalized = (folded_image - np.amin(folded_image))/(np.amax(folded_image) - np.amin(folded_image))\n",
    "    folded_org_image_array[folded_org_image_array>0] = 1\n",
    "    return(folded_org_image_array)\n",
    "\n",
    "folded_test_shape_array = fold_original_image_array(test_shape)\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "im = ax[0].imshow(test_shape[0], cmap='inferno')\n",
    "ax[0].set_title('Original image')\n",
    "plt.colorbar(im)\n",
    "\n",
    "im = ax[1].imshow(folded_test_shape_array[0], cmap='inferno')\n",
    "ax[1].set_title('Folded output')\n",
    "plt.colorbar(im)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fold_predicted_image_array(org_image_array):\n",
    "    # Return an array containing folding each 2d shape\n",
    "    folded_org_image_array = np.zeros((int(org_image_array.shape[0]),int(org_image_array.shape[1]/2),int(org_image_array.shape[2]) ))\n",
    "    for i in np.arange(len(org_image_array)):\n",
    "        image_top = org_image_array[i,0:int(org_image_array.shape[1]/2),:]\n",
    "        image_bottom = org_image_array[i,int(org_image_array.shape[1]/2):,:]\n",
    "        image_bottom_flip = np.flipud(image_bottom)\n",
    "        folded_org_image_array[i] = image_bottom_flip+image_top\n",
    "        folded_org_image_array[i] = (folded_org_image_array[i] - np.amin(folded_org_image_array[i]))/(np.amax(folded_org_image_array[i]) - np.amin(folded_org_image_array[i]))\n",
    "    folded_org_image_array[folded_org_image_array>=0.3] = 1\n",
    "    folded_org_image_array[folded_org_image_array<0.3] = 0\n",
    "    return(folded_org_image_array)\n",
    "\n",
    "folded_predicted_shape_array_SNR500 = fold_predicted_image_array(test_predict_shape_SNR500)\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "im = ax[0].imshow(test_predict_shape_SNR500[0], cmap='inferno')\n",
    "ax[0].set_title('Original image')\n",
    "plt.colorbar(im)\n",
    "\n",
    "im = ax[1].imshow(folded_predicted_shape_array_SNR500[0], cmap='inferno')\n",
    "ax[1].set_title('Folded output')\n",
    "plt.colorbar(im)\n",
    "\n",
    "# bin_px = np.linspace(0,1,10)\n",
    "# px = np.array(folded_predicted_shape_array_SNR500[0])\n",
    "# temp = px.flatten()\n",
    "# plt.hist(temp,bins=bin_px)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All the required codes for folding and calculating MSE\n",
    "\n",
    "def fold_original_image_array(org_image_array):\n",
    "    # Return an array containing folding each 2d shape\n",
    "    folded_org_image_array = np.zeros((int(org_image_array.shape[0]),int(org_image_array.shape[1]/2),int(org_image_array.shape[2]) ))\n",
    "    for i in np.arange(len(org_image_array)):\n",
    "        image_top = org_image_array[i,0:int(org_image_array.shape[1]/2),:]\n",
    "        image_bottom = org_image_array[i,int(org_image_array.shape[1]/2):,:]\n",
    "        image_bottom_flip = np.flipud(image_bottom)\n",
    "        folded_org_image_array[i] = image_bottom_flip+image_top\n",
    "    folded_org_image_array[folded_org_image_array>0] = 1\n",
    "    return(folded_org_image_array)\n",
    "\n",
    "def fold_predicted_image_array(org_image_array):\n",
    "    threshold = 0.3\n",
    "    # Return an array containing folding each 2d shape\n",
    "    folded_org_image_array = np.zeros((int(org_image_array.shape[0]),int(org_image_array.shape[1]/2),int(org_image_array.shape[2]) ))\n",
    "    for i in np.arange(len(org_image_array)):\n",
    "        image_top = org_image_array[i,0:int(org_image_array.shape[1]/2),:]\n",
    "        image_bottom = org_image_array[i,int(org_image_array.shape[1]/2):,:]\n",
    "        image_bottom_flip = np.flipud(image_bottom)\n",
    "        folded_org_image_array[i] = image_bottom_flip+image_top\n",
    "        folded_org_image_array[i] = (folded_org_image_array[i] - np.amin(folded_org_image_array[i]))/(np.amax(folded_org_image_array[i]) - np.amin(folded_org_image_array[i]))\n",
    "    folded_org_image_array[folded_org_image_array>=threshold] = 1\n",
    "    folded_org_image_array[folded_org_image_array<threshold] = 0\n",
    "    return(folded_org_image_array)\n",
    "\n",
    "def calc_MSE(ary1,ary2):\n",
    "    MSE = 0\n",
    "    if ary1.shape == ary2.shape:\n",
    "        for i in np.arange(len(ary1)):\n",
    "            MSE = MSE + np.mean((ary1[i] - ary2[i])**2)\n",
    "        MSE = MSE/len(ary1)\n",
    "        # print(\"MSE = \",MSE)\n",
    "        return(MSE)\n",
    "    else:\n",
    "        print(\"Given array shape not same\")\n",
    "\n",
    "# Fold the original shapes\n",
    "folded_test_shape_array = fold_original_image_array(test_shape)\n",
    "\n",
    "# Fold the predicted shapes for different SNR\n",
    "folded_predicted_shape_array_SNR500 = fold_predicted_image_array(test_predict_shape_SNR500)\n",
    "folded_predicted_shape_array_SNR200 = fold_predicted_image_array(test_predict_shape_SNR200)\n",
    "folded_predicted_shape_array_SNR150 = fold_predicted_image_array(test_predict_shape_SNR150)\n",
    "folded_predicted_shape_array_SNR100 = fold_predicted_image_array(test_predict_shape_SNR100)\n",
    "folded_predicted_shape_array_SNR75 = fold_predicted_image_array(test_predict_shape_SNR75)\n",
    "folded_predicted_shape_array_SNR50 = fold_predicted_image_array(test_predict_shape_SNR50)\n",
    "\n",
    "\n",
    "print(\"MSE without folding\")\n",
    "mse = calc_MSE(test_shape,test_predict_shape_SNR500)\n",
    "print(\"SNR = 500 -> \",mse)\n",
    "mse = calc_MSE(test_shape,test_predict_shape_SNR200)\n",
    "print(\"SNR = 200 -> \",mse)\n",
    "mse = calc_MSE(test_shape,test_predict_shape_SNR150)\n",
    "print(\"SNR = 150 -> \",mse)\n",
    "mse = calc_MSE(test_shape,test_predict_shape_SNR100)\n",
    "print(\"SNR = 100 -> \",mse)\n",
    "mse = calc_MSE(test_shape,test_predict_shape_SNR75)\n",
    "print(\"SNR = 75 -> \",mse)\n",
    "mse = calc_MSE(test_shape,test_predict_shape_SNR50)\n",
    "print(\"SNR = 50 -> \",mse)\n",
    "\n",
    "\n",
    "print(\"MSE after folding the shape\")\n",
    "mse = calc_MSE(folded_test_shape_array,folded_predicted_shape_array_SNR500)\n",
    "print(\"SNR = 500 -> \",mse)\n",
    "mse = calc_MSE(folded_test_shape_array,folded_predicted_shape_array_SNR200)\n",
    "print(\"SNR = 200 -> \",mse)\n",
    "mse = calc_MSE(folded_test_shape_array,folded_predicted_shape_array_SNR150)\n",
    "print(\"SNR = 150 -> \",mse)\n",
    "mse = calc_MSE(folded_test_shape_array,folded_predicted_shape_array_SNR100)\n",
    "print(\"SNR = 100 -> \",mse)\n",
    "mse = calc_MSE(folded_test_shape_array,folded_predicted_shape_array_SNR75)\n",
    "print(\"SNR = 75 -> \",mse)\n",
    "mse = calc_MSE(folded_test_shape_array,folded_predicted_shape_array_SNR50)\n",
    "print(\"SNR = 50 -> \",mse)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
