{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code is used to overlap simulated light curve and \n",
    "# Kepler Lightcurve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import TF and check for GPU\n",
    "\n",
    "import tensorflow as tf\n",
    "print(tf.config.list_physical_devices('GPU'))\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "\n",
    "# Import required libraries\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from tensorflow.keras.models import save_model, load_model\n",
    "import math\n",
    "import sys\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load kepler light curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = ['../data/tfr_shallue/tfr_all/tfrecord/train-00000-of-00008',\n",
    "             '../data/tfr_shallue/tfr_all/tfrecord/train-00001-of-00008',\n",
    "             '../data/tfr_shallue/tfr_all/tfrecord/train-00002-of-00008',\n",
    "             '../data/tfr_shallue/tfr_all/tfrecord/train-00003-of-00008',\n",
    "             '../data/tfr_shallue/tfr_all/tfrecord/train-00004-of-00008',\n",
    "             '../data/tfr_shallue/tfr_all/tfrecord/train-00005-of-00008',\n",
    "             '../data/tfr_shallue/tfr_all/tfrecord/train-00006-of-00008',\n",
    "             '../data/tfr_shallue/tfr_all/tfrecord/train-00007-of-00008',\n",
    "             '../data/tfr_shallue/tfr_all/tfrecord/val-00000-of-00001',\n",
    "             '../data/tfr_shallue/tfr_all/tfrecord/test-00000-of-00001']\n",
    "raw_dataset = tf.data.TFRecordDataset(filenames)\n",
    "raw_dataset\n",
    "\n",
    "feature_description = {\n",
    "    'global_view': tf.io.FixedLenSequenceFeature([], tf.float32, default_value=0.0,allow_missing=True),\n",
    "    'local_view': tf.io.FixedLenSequenceFeature([], tf.float32, default_value=0.0,allow_missing=True),\n",
    "    'av_training_set': tf.io.FixedLenFeature([], tf.string, default_value=''),\n",
    "    'kepid': tf.io.FixedLenSequenceFeature([], tf.int64, default_value=int(0),allow_missing=True),\n",
    "}\n",
    "\n",
    "def _parse_function(example_proto):\n",
    "  # Parse the input `tf.train.Example` proto using the dictionary above.\n",
    "  return tf.io.parse_single_example(example_proto, feature_description)\n",
    "\n",
    "# At this point the dataset contains serialized tf.train.Example messages.\n",
    "# When iterated over it returns these as scalar string tensors.\n",
    "# Use the .take method to only show the first 10 records.\n",
    "for raw_record in raw_dataset.take(10):\n",
    "  print(repr(raw_record))\n",
    "  \n",
    "parsed_dataset = raw_dataset.map(_parse_function)\n",
    "parsed_dataset\n",
    "\n",
    "\n",
    "# Calculate the size of one light curve corresponding to 'local_view'\n",
    "y = np.array([])\n",
    "for elem in parsed_dataset.take(1):\n",
    "  y = np.append(y,[elem['local_view']])\n",
    "length_lc = len(y)\n",
    "print(\"length_lc = \" ,length_lc)\n",
    "\n",
    "\n",
    "# Calculate total number of light curves\n",
    "no_data = 0\n",
    "for elem in parsed_dataset.as_numpy_iterator():\n",
    "    no_data = no_data + 1\n",
    "print('no_data = ',no_data)\n",
    "\n",
    "# Extract Kepler ID\n",
    "kepid_array = np.zeros(shape=(no_data,))\n",
    "i = 0\n",
    "for elem in parsed_dataset:\n",
    "    kepid_array[i] = elem['kepid'] \n",
    "    i = i + 1\n",
    "\n",
    "# lc_label_array - array containing labels\n",
    "lc_label_array = np.chararray(shape=(no_data,))\n",
    "\n",
    "i = 0\n",
    "for elem in parsed_dataset.as_numpy_iterator():\n",
    "    lc_label_array[i] = elem['av_training_set']\n",
    "    i = i + 1\n",
    "\n",
    "# convert all tf dataset to np array (light curve numpy array (lc_np_array))\n",
    "lc_np_array = np.zeros(shape=(no_data,length_lc))\n",
    "lc_np_array.shape\n",
    "\n",
    "i = 0\n",
    "for elem in parsed_dataset.as_numpy_iterator():\n",
    "    lc_np_array[i] = elem['local_view'] #+1.0\n",
    "    i = i + 1\n",
    "\n",
    "print('lc_np_array[0] = ',lc_np_array[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in np.arange(1):\n",
    "    j=981\n",
    "    test_lc = lc_np_array[j]\n",
    "    ph = np.linspace(-1.0,1.0,len(lc_np_array[0]))\n",
    "    plt.scatter(ph, test_lc)\n",
    "    print(int(kepid_array[j]))\n",
    "    plt.title(f\"{int(kepid_array[j])}| {lc_label_array[j]}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to select all the index of Kepler light curves with SNR > 50\n",
    "\n",
    "# Calculate SNR of all the lc in Kepler Dataset\n",
    "lc_np_array_offset = lc_np_array + 1\n",
    "noise_array = np.zeros((len(lc_np_array),120))\n",
    "for i in np.arange(len(lc_np_array)):\n",
    "    noise_array[i][0:60] = lc_np_array[i,0:60]\n",
    "    noise_array[i][60:120] = lc_np_array[i,141:202]\n",
    "std_devs_Kepler = np.array([np.std(arr) for arr in noise_array])\n",
    "SNR_Kepler = 1/std_devs_Kepler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to show the properties of the light curves in Kepler Dataset\n",
    "print(f\"Total no. of light curves in Kepler Dataset = \",len(SNR_Kepler))\n",
    "print(\"\\tTotal No. of planets = \",len(np.where(lc_label_array==b'P')[0]))\n",
    "print(\"\\tTotal no. of non-transiting phenomenon = \",len(np.where(lc_label_array==b'N')[0]))\n",
    "print(\"\\tTotal no. of astrophysical false positive = \",len(np.where(lc_label_array==b'A')[0]))\n",
    "print(\"\\n---\\n\")\n",
    "SNR_Threshold_array = [50,75,100,500]\n",
    "for SNR_Threshold in SNR_Threshold_array:\n",
    "    selected_kepler_index_mask = SNR_Kepler > SNR_Threshold\n",
    "    selected_kepler_index = np.where(selected_kepler_index_mask)[0]\n",
    "    print(f\"For SNR >  {SNR_Threshold}\")\n",
    "    print(f\"\\tNo. of light curves = \",len(selected_kepler_index))\n",
    "    # print(\"Index where label = Planet: \",np.where(lc_label_array[selected_kepler_index]==b'P')[0])\n",
    "    print(\"\\tNo. of planets = \",len(np.where(lc_label_array[selected_kepler_index]==b'P')[0]))\n",
    "    print(\"\\tNo. of non-transiting phenomenon = \",len(np.where(lc_label_array[selected_kepler_index]==b'N')[0]))\n",
    "    print(\"\\tNo. of astrophysical false positive = \",len(np.where(lc_label_array[selected_kepler_index]==b'A')[0]))\n",
    "\n",
    "    # print('selected_kepler_index_mask = ',selected_kepler_index_mask)\n",
    "    # print('selected_kepler_index = ',selected_kepler_index)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the index of the light curve with SNR > 50\n",
    "# select_kepler_lc = lc_np_array[SNR_Kepler>75]\n",
    "# select_kepler_lc = select_kepler_lc + 1\n",
    "\n",
    "SNR_Threshold = 500\n",
    "selected_kepler_index_mask = (SNR_Kepler > SNR_Threshold)  # & (SNR_Kepler < 500) \n",
    "selected_kepler_index = np.where(selected_kepler_index_mask)[0]\n",
    "print(f\"No. of light curves with SNR > {SNR_Threshold} = \",len(selected_kepler_index))\n",
    "print(f\"Total no. of light curves = \",len(SNR_Kepler))\n",
    "# Plot the selected light curves 3 x 3\n",
    "num = 3\n",
    "fig,ax=plt.subplots(num,3, figsize=(8,6), gridspec_kw={ 'width_ratios': [1,1,1],\n",
    "        'wspace': 0.2,'hspace': 0.4})\n",
    "\n",
    "# ax[0][1].set_title('Shape',size=15)\n",
    "# ax[0][0].set_title('Light Curve (Train Dataset)',size=15)\n",
    "# ax[num-1][0].set_xlabel('Phase',size=13)\n",
    "ph_kepler = np.linspace(-1,1,len(lc_np_array_offset[0]))\n",
    "\n",
    "\n",
    "i = 0\n",
    "for i in np.arange(0,num):\n",
    "    # k = np.random.randint(0, len(select_kepler_lc)-50)\n",
    "    k = int(np.random.choice(selected_kepler_index))\n",
    "    ax[i][0].set_title(f'SNR = {int(np.round(SNR_Kepler[k],0))} | {lc_label_array[k]}',size=13)\n",
    "    ax[i][0].set_ylim(-0.5,1.5)\n",
    "    ax[i][0].plot(ph_kepler, lc_np_array_offset[k],color = 'tab:red',linewidth='2')\n",
    "    ax[i][0].grid('on')\n",
    "\n",
    "    k = int(np.random.choice(selected_kepler_index))\n",
    "    ax[i][1].set_title(f'SNR = {int(np.round(SNR_Kepler[k],0))} | {lc_label_array[k]}',size=13)\n",
    "    ax[i][1].set_ylim(-0.5,1.5)\n",
    "    ax[i][1].plot(ph_kepler, lc_np_array_offset[k],color = 'tab:red',linewidth='2')\n",
    "    ax[i][1].grid('on')\n",
    "\n",
    "    k = int(np.random.choice(selected_kepler_index))\n",
    "    ax[i][2].set_title(f'SNR = {int(np.round(SNR_Kepler[k],0))} | {lc_label_array[k]}',size=13)\n",
    "    ax[i][2].set_ylim(-0.5,1.5)\n",
    "    ax[i][2].plot(ph_kepler, lc_np_array_offset[k],color = 'tab:red',linewidth='2')\n",
    "    ax[i][2].grid('on')\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code to shift the light curve to the centre\n",
    "\n",
    "# Check whether any index for phase axis phase is 0\n",
    "print('np.where(ph_kepler == 0)[0] = ', np.where(ph_kepler == 0)[0]) # OP: np.where(ph == 0)[0] =  [100]\n",
    "print('len(ph_kepler) = ',len(ph_kepler)) # OP: len(ph) =  201\n",
    "\n",
    "# Calculate the index where light curve is at minimum and shift it\n",
    "min_index = np.zeros(len(lc_np_array_offset))\n",
    "for iter in np.arange(len(lc_np_array_offset)):\n",
    "    min_index[iter] = np.argmin(lc_np_array_offset[iter])\n",
    "    # Calculate the number of positions to shift the array\n",
    "    shift_amount = len(lc_np_array_offset[iter]) // 2 - min_index[iter]\n",
    "\n",
    "    # Shift the array to bring the minimum value to the central index\n",
    "    lc_np_array_offset[iter] = np.roll(lc_np_array_offset[iter], int(shift_amount))\n",
    "    min_index[iter] = np.argmin(lc_np_array_offset[iter])\n",
    "\n",
    "# Plot the histogram of the index\n",
    "bins = np.linspace(0,201,202)\n",
    "\n",
    "plt.figure(figsize=(9, 9))\n",
    "# plt.hist(std_devs_Kepler, bins=bins, density=True, alpha=0.8, color='tab:green')\n",
    "a,*_ = np.histogram(min_index, bins=bins)\n",
    "# print('a = ',a)\n",
    "print('np.sum(a) = ', np.sum(a))\n",
    "a_percent = (a/np.sum(a))*100\n",
    "# print('a_percent = ',a_percent)\n",
    "\n",
    "plt.stairs(a_percent, bins, baseline=0,fill=True,color='black')\n",
    "plt.xlabel('Index')\n",
    "# plt.xscale(\"log\")\n",
    "plt.ylabel('Probability (%)')\n",
    "plt.title('Histogram - Index at where minimum occurs')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To plot the shifted lightcurves\n",
    "\n",
    "print(f\"Total no. of light curves = \",len(SNR_Kepler))\n",
    "# Plot the selected light curves 3 x 3\n",
    "num = 3\n",
    "fig,ax=plt.subplots(num,3, figsize=(8,6), gridspec_kw={ 'width_ratios': [1,1,1],\n",
    "        'wspace': 0.2,'hspace': 0.4})\n",
    "\n",
    "# ax[0][1].set_title('Shape',size=15)\n",
    "# ax[0][0].set_title('Light Curve (Train Dataset)',size=15)\n",
    "# ax[num-1][0].set_xlabel('Phase',size=13)\n",
    "ph_kepler = np.linspace(-1,1,len(lc_np_array_offset[0]))\n",
    "\n",
    "\n",
    "i = 0\n",
    "for i in np.arange(0,num):\n",
    "    # k = np.random.randint(0, len(select_kepler_lc)-50)\n",
    "    k = int(np.random.choice(selected_kepler_index))\n",
    "    ax[i][0].set_title(f'SNR = {int(np.round(SNR_Kepler[k],0))} | {lc_label_array[k]}',size=13)\n",
    "    ax[i][0].set_ylim(-0.5,1.5)\n",
    "    ax[i][0].plot(ph_kepler, lc_np_array_offset[k],color = 'tab:red',label='shifted',linewidth='2')\n",
    "    ax[i][0].plot(ph_kepler, lc_np_array[k]+1,color = 'tab:blue',label='original',linewidth='2')\n",
    "    ax[i][0].grid('on')\n",
    "#     ax[i][0].legend()\n",
    "\n",
    "\n",
    "    k = int(np.random.choice(selected_kepler_index))\n",
    "    ax[i][1].set_title(f'SNR = {int(np.round(SNR_Kepler[k],0))} | {lc_label_array[k]}',size=13)\n",
    "    ax[i][1].set_ylim(-0.5,1.5)\n",
    "    ax[i][1].plot(ph_kepler, lc_np_array_offset[k],color = 'tab:red',label='shifted',linewidth='2')\n",
    "    ax[i][1].plot(ph_kepler, lc_np_array[k]+1,color = 'tab:blue',label='original',linewidth='2')\n",
    "    ax[i][1].grid('on')\n",
    "#     ax[i][1].legend()\n",
    "\n",
    "\n",
    "    k = int(np.random.choice(selected_kepler_index))\n",
    "    ax[i][2].set_title(f'SNR = {int(np.round(SNR_Kepler[k],0))} | {lc_label_array[k]}',size=13)\n",
    "    ax[i][2].set_ylim(-0.5,1.5)\n",
    "    ax[i][2].plot(ph_kepler, lc_np_array_offset[k],color = 'tab:red',label='shifted',linewidth='2')\n",
    "    ax[i][2].plot(ph_kepler, lc_np_array[k]+1,color = 'tab:blue',label='original',linewidth='2')\n",
    "    ax[i][2].grid('on')\n",
    "    ax[i][2].legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
    "\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.logspace(0,5,60)\n",
    "\n",
    "plt.figure(figsize=(9, 9))\n",
    "# plt.hist(std_devs_Kepler, bins=bins, density=True, alpha=0.8, color='tab:green')\n",
    "a,*_ = np.histogram(SNR_Kepler, bins=bins)\n",
    "# print('a = ',a)\n",
    "print('np.sum(a) = ', np.sum(a))\n",
    "a_percent = (a/np.sum(a))*100\n",
    "# print('a_percent = ',a_percent)\n",
    "\n",
    "plt.stairs(a_percent, bins, baseline=0,fill=True,color='black')\n",
    "plt.xlabel('SNR')\n",
    "plt.xscale(\"log\")\n",
    "plt.ylabel('Probability (%)')\n",
    "plt.title('Histogram - SNR')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load simulation light curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load Dataset\n",
    "## Load Train Set\n",
    "# train_shape_dir = '../data/data_npy/shape_npy/shape_filled5.npy'\n",
    "# train_lc_dir = '../data/data_npy/lc_npy/lc_dict_5.npy'\n",
    "\n",
    "train_shape_dir = '../data/train/npy/shape/shape_5.npy'\n",
    "train_lc_dir =  '../data/train/npy/lc/lc_1_shape_5.npy'\n",
    "\n",
    "train_lc = np.load(train_lc_dir)\n",
    "train_shape = np.load(train_shape_dir)\n",
    "# Check equality of number of dataset\n",
    "if len(train_lc)==len(train_shape):\n",
    "    print(\"Train Set: No. of LC = No. of shapes\")\n",
    "else:\n",
    "    sys.exit(\"EXIT: Train Set: No. of LC != No. of shapes\")\n",
    "\n",
    "## Load Validation Set\n",
    "# vald_shape_dir = '../data/data_npy/shape_npy/shape_filled4.npy'\n",
    "# vald_lc_dir = '../data/data_npy/lc_npy/lc_dict_4.npy'\n",
    "\n",
    "vald_shape_dir = '../data/vald/npy/shape/shape_1.npy'\n",
    "vald_lc_dir = '../data/vald/npy/lc/lc_1_shape_1.npy'\n",
    "\n",
    "vald_lc = np.load(vald_lc_dir)\n",
    "vald_shape = np.load(vald_shape_dir)\n",
    "# Check equality of nuftmber of dataset\n",
    "if len(vald_lc)==len(vald_shape):\n",
    "    print(\"Vald Set: No. of LC = No. of shapes\")\n",
    "else:\n",
    "    sys.exit(\"Vald Set: No. of LC = No. of shapes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Normalize the image, convert to opacity map\n",
    "## Train Set\n",
    "train_shape = train_shape/np.amax(train_shape)\n",
    "train_shape_where_0 = np.where(train_shape == 0)\n",
    "train_shape_where_1 = np.where(train_shape == 1)\n",
    "train_shape[train_shape_where_0] = 1  # 1 represent the shape (1 opacity)\n",
    "train_shape[train_shape_where_1] = 0  # 0 represent background (0 opacity)\n",
    "\n",
    "## Valdn Set\n",
    "vald_shape = vald_shape/np.amax(vald_shape)\n",
    "vald_shape_where_0 = np.where(vald_shape == 0)\n",
    "vald_shape_where_1 = np.where(vald_shape == 1)\n",
    "vald_shape[vald_shape_where_0] = 1  # 1 represent the shape (1 opacity)\n",
    "vald_shape[vald_shape_where_1] = 0  # 0 represent background (0 opacity)\n",
    "print(\"Normalized the shape\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Normalize the lightcurves\n",
    "## - Train Set\n",
    "train_lc_scaled = np.zeros(train_lc.shape)\n",
    "for i in np.arange(len(train_lc_scaled)):\n",
    "    train_lc_scaled[i] = (train_lc[i] - np.amin(train_lc[i]))/(np.amax(train_lc[i]) - np.amin(train_lc[i]))\n",
    "\n",
    "## - Vald Set\n",
    "vald_lc_scaled = np.zeros(vald_lc.shape)\n",
    "for i in np.arange(len(vald_lc_scaled)):\n",
    "    vald_lc_scaled[i] = (vald_lc[i] - np.amin(vald_lc[i]))/(np.amax(vald_lc[i]) - np.amin(vald_lc[i]))\n",
    "print(\"Normalized the light curves\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add flat line towards left and right of dip\n",
    "# 10 data points on each side\n",
    "# 3. Extend the lightcurves\n",
    "## - Train Set\n",
    "train_lc_scaled_append = np.ones((train_lc.shape[0],120))\n",
    "print('train_lc_scaled_append.shape = ',train_lc_scaled_append.shape)\n",
    "print(\"len(train_lc_scaled_append[0,10:110]) = \",len(train_lc_scaled_append[0,10:110]))\n",
    "\n",
    "for i in np.arange(len(train_lc_scaled)):\n",
    "    train_lc_scaled_append[i,10:110] = train_lc_scaled[i]\n",
    "\n",
    "## - Vald Set\n",
    "vald_lc_scaled_append = np.ones((vald_lc.shape[0],120))\n",
    "for i in np.arange(len(vald_lc_scaled)):\n",
    "    vald_lc_scaled_append[i,10:110] = vald_lc_scaled[i]\n",
    "print(\"Extended the light curves\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verification\n",
    "# Plot - Train LCs\n",
    "num = 3\n",
    "fig,ax=plt.subplots(num,2, figsize=(4,3), gridspec_kw={ 'width_ratios': [2,1],\n",
    "        'wspace': 0.2,'hspace': 0.4})\n",
    "\n",
    "ax[0][1].set_title('Shape',size=15)\n",
    "ax[0][0].set_title('Light Curve (Train Dataset)',size=15)\n",
    "ax[num-1][0].set_xlabel('Phase',size=13)\n",
    "ph_simul = np.linspace(-1,1,len(train_lc_scaled_append[0]))\n",
    "# advance = 60\n",
    "\n",
    "i = 0\n",
    "for i in np.arange(0,num):\n",
    "    k = np.random.randint(0, len(train_lc_scaled_append)-1)\n",
    "    ax[i][1].tick_params(left = False, right = False , labelleft = False ,labelbottom = False, bottom = False)\n",
    "    if(i<num-1): ax[i][0].tick_params(labelbottom = False, bottom = False)\n",
    "    img = ax[i][1].imshow(train_shape[k],cmap='inferno')\n",
    "    plt.colorbar(img)\n",
    "    ax[i][0].set_ylabel('Flux',size=13)\n",
    "    ax[i][0].set_ylim(-0.5,1.5)\n",
    "#     ax[i][0].scatter(ph, vald_lc_scaled_append[k],color = 'black',marker='.')\n",
    "    ax[i][0].plot(ph_simul, train_lc_scaled_append[k],color = 'tab:red',linewidth='2')\n",
    "    ax[i][0].grid('on')\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verification\n",
    "# Plot - vald LCs\n",
    "num = 3\n",
    "fig,ax=plt.subplots(num,2, figsize=(4,3), gridspec_kw={ 'width_ratios': [2,1],\n",
    "        'wspace': 0.2,'hspace': 0.4})\n",
    "\n",
    "ax[0][1].set_title('Shape',size=15)\n",
    "ax[0][0].set_title('Light Curve (vald Dataset)',size=15)\n",
    "ax[num-1][0].set_xlabel('Phase',size=13)\n",
    "ph = np.linspace(-1,1,len(vald_lc_scaled_append[0]))\n",
    "# advance = 60\n",
    "\n",
    "i = 0\n",
    "for i in np.arange(0,num):\n",
    "    k = np.random.randint(0, len(vald_lc_scaled_append)-1)\n",
    "    ax[i][1].tick_params(left = False, right = False , labelleft = False ,labelbottom = False, bottom = False)\n",
    "    if(i<num-1): ax[i][0].tick_params(labelbottom = False, bottom = False)\n",
    "    img = ax[i][1].imshow(vald_shape[k],cmap='inferno')\n",
    "    plt.colorbar(img)\n",
    "    ax[i][0].set_ylabel('Flux',size=13)\n",
    "    ax[i][0].set_ylim(-0.5,1.5)\n",
    "#     ax[i][0].scatter(ph, vald_lc_scaled_append[k],color = 'black',marker='.')\n",
    "    ax[i][0].plot(ph_simul, vald_lc_scaled_append[k],color = 'tab:red',linewidth='2')\n",
    "    ax[i][0].grid('on')\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(ph_simul,train_lc_scaled_append[0],label='Simulated LC')\n",
    "plt.plot(ph_kepler,lc_np_array_offset[selected_kepler_index[0]],label=f\"{kepid_array[selected_kepler_index[0]]}\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(ph_simul,train_lc_scaled_append[29],label='Simulated LC',linewidth=2,color='black')\n",
    "kep_id_scale = int(np.random.choice(selected_kepler_index))\n",
    "\n",
    "for iter in np.linspace(0,20,20,dtype=int):\n",
    "    \n",
    "    start_index = (iter*5)\n",
    "    stop_index = len(lc_np_array_offset[kep_id_scale]) - (iter*5)\n",
    "    lc_scale_test = lc_np_array_offset[kep_id_scale][start_index:stop_index]\n",
    "    ph_kepler_scale = np.linspace(-1,1,len(lc_scale_test))\n",
    "    if iter == 0:\n",
    "        plt.plot(ph_kepler_scale,lc_scale_test,label=f\"{kepid_array[kep_id_scale]} - Original\",color='tab:red',linewidth=3)\n",
    "    elif iter%2==0:\n",
    "        plt.plot(ph_kepler_scale,lc_scale_test,label=f\"Iter = {iter}\",color='tab:blue')\n",
    "plt.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of \"1\"s to append on both sides\n",
    "num_ones = 500\n",
    "\n",
    "# Create arrays of \"1\"s for left and right sides\n",
    "left_ones = np.ones(num_ones, dtype=int)\n",
    "right_ones = np.ones(num_ones, dtype=int)\n",
    "\n",
    "# Append \"1\"s to the left and right\n",
    "lc_temp = train_lc_scaled_append[np.random.randint(len(train_lc_scaled_append))]\n",
    "extended_lc_temp = np.concatenate((left_ones, lc_temp, right_ones))\n",
    "extende_ph_simul = np.linspace(-1,1,len(extended_lc_temp))\n",
    "plt.plot(ph_simul,lc_temp,label='Simulated LC',linewidth=2,color='red')\n",
    "plt.plot(extende_ph_simul,extended_lc_temp,label='Extended Simulated LC',linewidth=2,color='black')\n",
    "kep_id_scale = int(np.random.choice(selected_kepler_index))\n",
    "lc_scale_test = lc_np_array_offset[kep_id_scale]\n",
    "ph_kepler_scale = np.linspace(-1,1,len(lc_scale_test))\n",
    "plt.plot(ph_kepler_scale,lc_scale_test,label=\"Kepler LC\",linewidth=2,color='tab:blue')\n",
    "plt.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
